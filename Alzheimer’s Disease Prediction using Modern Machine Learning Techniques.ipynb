{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154b4833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from class MildDemented\n",
      "Loading images from class ModerateDemented\n",
      "Loading images from class NonDemented\n",
      "Loading images from class VeryMildDemented\n",
      "Loading images from class MildDemented\n",
      "Loading images from class ModerateDemented\n",
      "Loading images from class NonDemented\n",
      "Loading images from class VeryMildDemented\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Set the directories for the training and test datasets\n",
    "train_dir = 'C:/Users/Ayush/Desktop/Alzheimer_s Dataset/train/'\n",
    "test_dir = 'C:/Users/Ayush/Desktop/Alzheimer_s Dataset/test/'\n",
    "\n",
    "# Set the image dimensions\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Define the number of images to load from each class\n",
    "num_images_per_class = 500\n",
    "\n",
    "# Initialize the training and test data and labels\n",
    "X_train = np.zeros((num_classes * num_images_per_class, img_width, img_height, 3))\n",
    "y_train = np.zeros(num_classes * num_images_per_class, dtype='uint8')\n",
    "X_test = np.zeros((num_classes * num_images_per_class, img_width, img_height, 3))\n",
    "y_test = np.zeros(num_classes * num_images_per_class, dtype='uint8')\n",
    "\n",
    "# Define the classes and their corresponding labels\n",
    "classes = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "labels = [0, 1, 2, 3]\n",
    "\n",
    "# Load and preprocess each image from the training directory\n",
    "for i, c in enumerate(classes):\n",
    "    print(f'Loading images from class {c}')\n",
    "    image_dir = os.path.join(train_dir, c)\n",
    "    img_filenames = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    for j, img_filename in enumerate(img_filenames[:num_images_per_class]):\n",
    "        img_path = os.path.join(image_dir, img_filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((img_width, img_height))\n",
    "        img = np.array(img)\n",
    "        if img.ndim == 2:\n",
    "            # Convert grayscale images to RGB\n",
    "            img = np.stack([img] * 3, axis=-1)\n",
    "        X_train[i*num_images_per_class + j, :, :, :] = img\n",
    "        y_train[i*num_images_per_class + j] = i\n",
    "\n",
    "# Load and preprocess each image from the test directory\n",
    "for i, c in enumerate(classes):\n",
    "    print(f'Loading images from class {c}')\n",
    "    image_dir = os.path.join(test_dir, c)\n",
    "    img_filenames = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    for j, img_filename in enumerate(img_filenames[:num_images_per_class]):\n",
    "        img_path = os.path.join(image_dir, img_filename)\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((img_width, img_height))\n",
    "        img = np.array(img)\n",
    "        if img.ndim == 2:\n",
    "            # Convert grayscale images to RGB\n",
    "            img = np.stack([img] * 3, axis=-1)\n",
    "        X_test[i*num_images_per_class + j, :, :, :] = img\n",
    "        y_test[i*num_images_per_class + j] = i\n",
    "\n",
    "# Save the preprocessed data and labels to an NPZ file\n",
    "np.savez('alzheimer_images.npz', X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b800efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('alzheimer_images.npz', X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800b4e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 114ms/step - loss: 1191.0604 - accuracy: 0.5775 - val_loss: 192.6703 - val_accuracy: 0.6975\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 149.5536 - accuracy: 0.7225 - val_loss: 178.3043 - val_accuracy: 0.6100\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 80.3782 - accuracy: 0.7706 - val_loss: 156.5552 - val_accuracy: 0.6300\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 87.0395 - accuracy: 0.7844 - val_loss: 59.4507 - val_accuracy: 0.8025\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 49.0983 - accuracy: 0.8481 - val_loss: 50.3339 - val_accuracy: 0.8300\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 85.3181 - accuracy: 0.8087 - val_loss: 90.6371 - val_accuracy: 0.8025\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 130.0530 - accuracy: 0.7937 - val_loss: 236.2646 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 219.6144 - accuracy: 0.7444 - val_loss: 63.3567 - val_accuracy: 0.8025\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 80.2191 - accuracy: 0.8344 - val_loss: 105.1473 - val_accuracy: 0.8075\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 74.5656 - accuracy: 0.8625 - val_loss: 24.3255 - val_accuracy: 0.9300\n",
      "13/13 - 0s - loss: 24.3255 - accuracy: 0.9300 - 235ms/epoch - 18ms/step\n",
      "\n",
      "Test accuracy: 0.9300000071525574\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('C:/Users/Ayush/Desktop/python/alzheimer_images.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the ANN architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09a7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('C:/Users/Ayush/Desktop/python/alzheimer_images.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "# Flatten the images to 1D arrays\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "accuracy = logreg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dfb3bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "data = np.load('C:/Users/Ayush/Desktop/python/alzheimer_images.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "# Flatten the images to 1D\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Shuffle the data\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * X.shape[0])\n",
    "X_train, y_train = X[:split_index], y[:split_index]\n",
    "X_test, y_test = X[split_index:], y[split_index:]\n",
    "\n",
    "# Define and train KNN model\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5a0f201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load data\n",
    "data = np.load('C:/Users/Ayush/Desktop/python/alzheimer_images.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "# Flatten the images to 1D\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Shuffle the data\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Split into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * X.shape[0])\n",
    "X_train, y_train = X[:split_index], y[:split_index]\n",
    "X_test, y_test = X[split_index:], y[split_index:]\n",
    "\n",
    "# Define and train the model\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
